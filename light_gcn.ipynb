{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch.nn import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userid gender  age  occupation zipcode\n",
      "0       1      F    1          10   48067\n",
      "1       2      M   56          16   70072\n",
      "2       3      M   25          15   55117\n",
      "3       4      M   45           7   02460\n",
      "4       5      M   25          20   55455\n",
      "   movieid                               title                        genres\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "   userid  movieid  rating  timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n"
     ]
    }
   ],
   "source": [
    "user_columns = ['userid', 'gender', 'age', 'occupation', 'zipcode']\n",
    "movie_columns = ['movieid', 'title', 'genres']\n",
    "rating_columns = ['userid', 'movieid', 'rating', 'timestamp']\n",
    "\n",
    "users = pd.read_csv('ml-1m/users.dat', sep='::', header=None, names=user_columns, engine='python', encoding='ISO-8859-1')\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', header=None, names=movie_columns, engine='python', encoding='ISO-8859-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None, names=rating_columns, engine='python', encoding='ISO-8859-1')\n",
    "\n",
    "print(users.head())\n",
    "print(movies.head())\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocupation_dict = {\n",
    "    0: \"other\",\n",
    "    1: \"academic/educator\",\n",
    "    2: \"artist\",\n",
    "    3: \"clerical/admin\",\n",
    "    4: \"college/grad student\",\n",
    "    5: \"customer service\",\n",
    "    6: \"doctor/health care\",\n",
    "    7: \"executive/managerial\",\n",
    "    8: \"farmer\",\n",
    "    9: \"homemaker\",\n",
    "    10: \"K-12 student\",\n",
    "    11: \"lawyer\",\n",
    "    12: \"programmer\",\n",
    "    13: \"retired\",\n",
    "    14: \"sales/marketing\",\n",
    "    15: \"scientist\",\n",
    "    16: \"self-employed\",\n",
    "    17: \"technician/engineer\",\n",
    "    18: \"tradesman/craftsman\",\n",
    "    19: \"unemployed\",\n",
    "    20: \"writer\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_splitters import python_stratified_split\n",
    "train_ratings, test_ratings = python_stratified_split(ratings, ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ratings['userid'].max()\n",
    "num_movies = ratings['movieid'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the pre-trained SentenceTransformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for movie genres\n",
    "movies['genres list'] = movies['genres'].apply(lambda x: x.split('|'))\n",
    "movies['genres list'] = movies['genres list'].apply(lambda x: ' '.join(x))\n",
    "genres_embeddings = model.encode(movies['genres list'].tolist())\n",
    "\n",
    "# Generate embeddings for user occupations\n",
    "occupations_embeddings = model.encode(users['occupation'].apply(lambda x: ocupation_dict[x]).tolist())\n",
    "\n",
    "# Convert embeddings to tensors\n",
    "genres_embeddings_tensor = torch.tensor(genres_embeddings, dtype=torch.float)\n",
    "occupations_embeddings_tensor = torch.tensor(occupations_embeddings, dtype=torch.float)\n",
    "\n",
    "movies['genres embeddings'] = list(genres_embeddings_tensor)\n",
    "users['occupation embeddings'] = list(occupations_embeddings_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3883"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['movieid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>750121.000000</td>\n",
       "      <td>750121.000000</td>\n",
       "      <td>750121.000000</td>\n",
       "      <td>7.501210e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3024.528364</td>\n",
       "      <td>1864.902114</td>\n",
       "      <td>3.582239</td>\n",
       "      <td>9.722435e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1728.394286</td>\n",
       "      <td>1095.640590</td>\n",
       "      <td>1.116519</td>\n",
       "      <td>1.215285e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.567039e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1506.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.653026e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3070.000000</td>\n",
       "      <td>1834.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.730180e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4476.000000</td>\n",
       "      <td>2770.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.752211e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6040.000000</td>\n",
       "      <td>3952.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.046455e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userid        movieid         rating     timestamp\n",
       "count  750121.000000  750121.000000  750121.000000  7.501210e+05\n",
       "mean     3024.528364    1864.902114       3.582239  9.722435e+08\n",
       "std      1728.394286    1095.640590       1.116519  1.215285e+07\n",
       "min         1.000000       1.000000       1.000000  9.567039e+08\n",
       "25%      1506.000000    1029.000000       3.000000  9.653026e+08\n",
       "50%      3070.000000    1834.000000       4.000000  9.730180e+08\n",
       "75%      4476.000000    2770.000000       4.000000  9.752211e+08\n",
       "max      6040.000000    3952.000000       5.000000  1.046455e+09"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "# Create edge index for bipartite graph for train set\n",
    "train_user_ids = train_ratings['userid'].values - 1  \n",
    "train_movie_ids = train_ratings['movieid'].values - 1 + num_users \n",
    "train_edge_index = torch.tensor([train_user_ids, train_movie_ids], dtype=torch.long)\n",
    "\n",
    "# Create edge index for bipartite graph for test set\n",
    "test_user_ids = test_ratings['userid'].values - 1  \n",
    "test_movie_ids = test_ratings['movieid'].values - 1 + num_users  \n",
    "test_edge_index = torch.tensor([test_user_ids, test_movie_ids], dtype=torch.long)\n",
    "\n",
    "# Create node features for users and movies for train set\n",
    "# train_user_features = occupations_embeddings_tensor.clone().detach()\n",
    "# train_movie_features = genres_embeddings_tensor.clone().detach()\n",
    "# print(train_user_features.shape)\n",
    "# print(train_movie_features.shape)\n",
    "\n",
    "# # Combine user and movie features into a single tensor for train set\n",
    "# X_train = torch.cat([train_user_features, train_movie_features], dim=0)\n",
    "# print(X_train.shape)\n",
    "\n",
    "# # Create node features for users and movies for test set\n",
    "# test_user_features = occupations_embeddings_tensor.clone().detach()\n",
    "# test_movie_features = genres_embeddings_tensor.clone().detach()\n",
    "\n",
    "# # Combine user and movie features into a single tensor for test set\n",
    "# X_test = torch.cat([test_user_features, test_movie_features], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings['movieid'].max()\n",
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class LightGCN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add') \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Start propagating messages.\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCNStack(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(num_nodes, embedding_dim)\n",
    "        self.convs = torch.nn.ModuleList([LightGCN(embedding_dim, embedding_dim) for _ in range(num_layers)])\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        x = self.embedding.weight\n",
    "        all_embeddings = [x]\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            all_embeddings.append(x)\n",
    "        \n",
    "        # Aggregate embeddings with factors a_k = 1/(k+1)\n",
    "        out = sum((1.0 / (k + 1)) * emb for k, emb in enumerate(all_embeddings))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(model, users, pos_items, neg_items):\n",
    "    user_emb = model.embedding(users)\n",
    "    pos_emb = model.embedding(pos_items)\n",
    "    neg_emb = model.embedding(neg_items)\n",
    "    \n",
    "    pos_scores = (user_emb * pos_emb).sum(dim=1)\n",
    "    neg_scores = (user_emb * neg_emb).sum(dim=1)\n",
    "    \n",
    "    loss = -F.logsigmoid(pos_scores - neg_scores).mean()\n",
    "    return loss\n",
    "\n",
    "def train(model, edge_index, users, pos_items, neg_items, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model(edge_index)\n",
    "    loss = bpr_loss(model, users, pos_items, neg_items)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_user_movie_interactions(ratings_df):\n",
    "    \"\"\"\n",
    "    Create a user-movie interaction graph from the ratings dataframe.\n",
    "    Include all interactions regardless of rating.\n",
    "    \"\"\"\n",
    "    user_movie_dict = defaultdict(list)\n",
    "    for user_id, movie_id, rating in zip(ratings_df['userid'], ratings_df['movieid'], ratings_df['rating']):\n",
    "        user_movie_dict[user_id].append((movie_id, rating))\n",
    "    return user_movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_movie_dict = build_user_movie_interactions(train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_threshold = 4\n",
    "negative_threshold = 2\n",
    "num_neg_samples = 5\n",
    "\n",
    "def sample_positive_and_negative_samples(user_movie_dict, positive_threshold, negative_threshold, num_neg_samples):\n",
    "\n",
    "    user_ratings = []\n",
    "\n",
    "    for user_id, movies in user_movie_dict.items():\n",
    "        pos_movies = [movie_id for movie_id, rating in movies if rating >= positive_threshold]\n",
    "        neg_movies = [movie_id for movie_id, rating in movies if rating <= negative_threshold]\n",
    "        \n",
    "        if len(pos_movies) == 0 or len(neg_movies) == 0:\n",
    "            continue\n",
    "        \n",
    "        user_ratings.append((user_id, pos_movies, neg_movies))\n",
    "        \n",
    "    return user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = sample_positive_and_negative_samples(train_user_movie_dict, positive_threshold, negative_threshold, num_neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dummy data for illustration\n",
    "# edge_index = torch.tensor([[0, 1, 2], [1, 2, 0]], dtype=torch.long)\n",
    "# users = torch.tensor([0, 1, 2], dtype=torch.long)\n",
    "# pos_items = torch.tensor([1, 2, 0], dtype=torch.long)\n",
    "# neg_items = torch.tensor([2, 0, 1], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index 9932 is out of bounds for dimension 0 with size 9923",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     pos_samples \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(pos_movies, no_sample)\n\u001b[1;32m     17\u001b[0m     neg_samples \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(neg_movies, no_sample)\n\u001b[0;32m---> 19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     22\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(user_ratings)\n",
      "Cell \u001b[0;32mIn[113], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, edge_index, users, pos_items, neg_items, optimizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m bpr_loss(model, users, pos_items, neg_items)\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[112], line 12\u001b[0m, in \u001b[0;36mLightGCNStack.forward\u001b[0;34m(self, edge_index)\u001b[0m\n\u001b[1;32m     10\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [x]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[0;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     all_embeddings\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Aggregate embeddings with factors a_k = 1/(k+1)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[111], line 16\u001b[0m, in \u001b[0;36mLightGCN.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# x has shape [N, in_channels]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# edge_index has shape [2, E]\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Compute normalization.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m edge_index\n\u001b[0;32m---> 16\u001b[0m     deg \u001b[38;5;241m=\u001b[39m \u001b[43mdegree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     18\u001b[0m     deg_inv_sqrt[deg_inv_sqrt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/utils/_degree.py:31\u001b[0m, in \u001b[0;36mdegree\u001b[0;34m(index, num_nodes, dtype)\u001b[0m\n\u001b[1;32m     29\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((N, ), dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mindex\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     30\u001b[0m one \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mout\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mout\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index 9932 is out of bounds for dimension 0 with size 9923"
     ]
    }
   ],
   "source": [
    "num_nodes = X_train.size(0)\n",
    "embedding_dim = X_train.size(1)\n",
    "num_layers = 12\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "sample_size = 32\n",
    "\n",
    "model = LightGCNStack(num_nodes, embedding_dim, num_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for user_id, pos_movies, neg_movies in user_ratings:\n",
    "        no_sample = min(sample_size, len(pos_movies), len(neg_movies))\n",
    "        users = torch.tensor([user_id] * no_sample, dtype=torch.long)\n",
    "        pos_samples = random.sample(pos_movies, no_sample)\n",
    "        neg_samples = random.sample(neg_movies, no_sample)\n",
    "        \n",
    "        loss = train(model, train_edge_index, users, pos_samples, neg_samples, optimizer)\n",
    "        total_loss += loss\n",
    "\n",
    "    avg_loss = total_loss / len(user_ratings)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9991\n"
     ]
    }
   ],
   "source": [
    "print(max(train_movie_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
