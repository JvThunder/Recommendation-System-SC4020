{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremy/anaconda3/envs/gnn/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from models.light_gcn import LightGCNStack\n",
    "from utils.graph_splitters import python_stratified_split\n",
    "from utils.light_gcn_utils import bpr_loss, evaluate, build_user_movie_interactions, get_positive_negative_ratings, recall_at_k, precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userid gender  age  occupation zipcode\n",
      "0       1      F    1          10   48067\n",
      "1       2      M   56          16   70072\n",
      "2       3      M   25          15   55117\n",
      "3       4      M   45           7   02460\n",
      "4       5      M   25          20   55455\n",
      "   movieid                               title                        genres\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "   userid  movieid  rating  timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n"
     ]
    }
   ],
   "source": [
    "user_columns = ['userid', 'gender', 'age', 'occupation', 'zipcode']\n",
    "movie_columns = ['movieid', 'title', 'genres']\n",
    "rating_columns = ['userid', 'movieid', 'rating', 'timestamp']\n",
    "\n",
    "users = pd.read_csv('ml-1m/users.dat', sep='::', header=None, names=user_columns, engine='python', encoding='ISO-8859-1')\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', header=None, names=movie_columns, engine='python', encoding='ISO-8859-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None, names=rating_columns, engine='python', encoding='ISO-8859-1')\n",
    "\n",
    "print(users.head())\n",
    "print(movies.head())\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ratings['userid'].nunique()\n",
    "num_movies = ratings['movieid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user reindexing\n",
    "user_to_index = {user: i+1 for i, user in enumerate(users['userid'])}\n",
    "\n",
    "# reindex userid in users and ratings\n",
    "users['userid'] = users['userid'].map(user_to_index)\n",
    "ratings['userid'] = ratings['userid'].map(user_to_index)\n",
    "\n",
    "# movie reindexing\n",
    "movie_to_index = {movie: i+1 for i, movie in enumerate(movies['movieid'])}\n",
    "\n",
    "# reindex movieid in movies and ratings\n",
    "movies['movieid'] = movies['movieid'].map(movie_to_index)\n",
    "ratings['movieid'] = ratings['movieid'].map(movie_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_dict = {\n",
    "    0: \"other\",\n",
    "    1: \"academic/educator\",\n",
    "    2: \"artist\",\n",
    "    3: \"clerical/admin\",\n",
    "    4: \"college/grad student\",\n",
    "    5: \"customer service\",\n",
    "    6: \"doctor/health care\",\n",
    "    7: \"executive/managerial\",\n",
    "    8: \"farmer\",\n",
    "    9: \"homemaker\",\n",
    "    10: \"K-12 student\",\n",
    "    11: \"lawyer\",\n",
    "    12: \"programmer\",\n",
    "    13: \"retired\",\n",
    "    14: \"sales/marketing\",\n",
    "    15: \"scientist\",\n",
    "    16: \"self-employed\",\n",
    "    17: \"technician/engineer\",\n",
    "    18: \"tradesman/craftsman\",\n",
    "    19: \"unemployed\",\n",
    "    20: \"writer\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the pre-trained SentenceTransformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for movie genres\n",
    "movies['genres list'] = movies['genres'].apply(lambda x: x.split('|'))\n",
    "movies['genres list'] = movies['genres list'].apply(lambda x: ' '.join(x))\n",
    "genres_embeddings = model.encode(movies['genres list'].tolist())\n",
    "\n",
    "# Generate embeddings for user occupations\n",
    "occupations_embeddings = model.encode(users['occupation'].apply(lambda x: occupation_dict[x]).tolist())\n",
    "\n",
    "# Convert embeddings to tensors\n",
    "movies_features_tensor = torch.tensor(genres_embeddings, dtype=torch.float)\n",
    "user_features_tensor = torch.tensor(occupations_embeddings, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings, test_ratings = python_stratified_split(ratings, ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_332086/3017330008.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  train_edge_index = torch.tensor([train_user_ids, train_movie_ids], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# Create edge index for bipartite graph for train set\n",
    "train_user_ids = train_ratings['userid'].values - 1  \n",
    "train_movie_ids = train_ratings['movieid'].values - 1 + num_users \n",
    "train_edge_index = torch.tensor([train_user_ids, train_movie_ids], dtype=torch.long)\n",
    "\n",
    "# Create edge index for bipartite graph for test set\n",
    "test_user_ids = test_ratings['userid'].values - 1  \n",
    "test_movie_ids = test_ratings['movieid'].values - 1 + num_users  \n",
    "test_edge_index = torch.tensor([test_user_ids, test_movie_ids], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_movie_dict = build_user_movie_interactions(train_ratings, 'userid', 'movieid', 'rating')\n",
    "test_user_movie_dict = build_user_movie_interactions(test_ratings, 'userid', 'movieid', 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_threshold = 5\n",
    "negative_threshold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_ratings = get_positive_negative_ratings(train_user_movie_dict, positive_threshold, negative_threshold)\n",
    "test_user_ratings = get_positive_negative_ratings(test_user_movie_dict, positive_threshold, negative_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 384\n",
    "num_nodes = num_users + num_movies\n",
    "no_user_features = user_features_tensor.size(1)\n",
    "no_movie_features = movies_features_tensor.size(1)\n",
    "\n",
    "num_layers = 10\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0005\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "user_features_tensor = user_features_tensor.to(device)\n",
    "movies_features_tensor = movies_features_tensor.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "\n",
    "model = LightGCNStack(num_nodes, no_user_features, no_movie_features, embedding_dim, num_layers).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base recall: 0.10923737152205612\n",
      "Base precision: 0.31719449225473323\n"
     ]
    }
   ],
   "source": [
    "embeddings = model(user_features_tensor, movies_features_tensor, train_edge_index)\n",
    "recall = recall_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "precision = precision_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "\n",
    "print(\"Base recall:\", recall)\n",
    "print(\"Base precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 5972/5972 [00:28<00:00, 209.55it/s, Avg Loss=0.6944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.6944, Recall@10: 0.1092, Precision@10: 0.3172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100:  12%|█▏        | 732/5972 [00:03<00:27, 190.95it/s, Avg Loss=0.6930]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m neg_samples \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(neg_movies, no_sample)\n\u001b[1;32m     14\u001b[0m neg_samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(neg_samples, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mbpr_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     18\u001b[0m num_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/mlai/rec-systems/Recommendation-System-SC4020/utils/light_gcn_utils.py:29\u001b[0m, in \u001b[0;36mbpr_loss\u001b[0;34m(embeddings, users, pos_items, neg_items)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbpr_loss\u001b[39m(embeddings, users, pos_items, neg_items):\n\u001b[1;32m     28\u001b[0m     user_emb \u001b[38;5;241m=\u001b[39m embeddings[users]\n\u001b[0;32m---> 29\u001b[0m     pos_emb \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos_items\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     30\u001b[0m     neg_emb \u001b[38;5;241m=\u001b[39m embeddings[neg_items]\n\u001b[1;32m     32\u001b[0m     pos_scores \u001b[38;5;241m=\u001b[39m (user_emb \u001b[38;5;241m*\u001b[39m pos_emb)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    pbar = tqdm(train_user_ratings, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    embeddings = model(user_features_tensor, movies_features_tensor, train_edge_index)\n",
    "\n",
    "    for user_id, pos_movies, neg_movies in pbar:\n",
    "        no_sample = min(len(pos_movies), len(neg_movies))\n",
    "        users = torch.tensor([user_id] * no_sample, dtype=torch.long).to(device)\n",
    "        pos_samples = random.sample(pos_movies, no_sample)\n",
    "        pos_samples = torch.tensor(pos_samples, dtype=torch.long).to(device)\n",
    "        neg_samples = random.sample(neg_movies, no_sample)\n",
    "        neg_samples = torch.tensor(neg_samples, dtype=torch.long).to(device)\n",
    "        \n",
    "        loss = bpr_loss(embeddings, users, pos_samples, neg_samples)\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "        avg_loss = total_loss.item() / num_batches\n",
    "\n",
    "        pbar.set_postfix({'Avg Loss': f'{avg_loss:.4f}'})\n",
    "\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    recall = recall_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "    precision = precision_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "    avg_loss = total_loss / len(train_user_ratings)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Recall@{k}: {recall:.4f}, Precision@{k}: {precision:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5539 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5539/5539 [00:25<00:00, 215.44it/s, Avg Loss=0.6925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6925, Test Recall@10: 0.1138, Test Precision@10: 0.3305\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "num_batches = 0\n",
    "pbar = tqdm(test_user_ratings)\n",
    "\n",
    "embeddings = model(user_features_tensor, movies_features_tensor, test_edge_index)\n",
    "\n",
    "for user_id, pos_movies, neg_movies in pbar:\n",
    "    no_sample = min(len(pos_movies), len(neg_movies))\n",
    "    users = torch.tensor([user_id] * no_sample, dtype=torch.long).to(device)\n",
    "    pos_samples = random.sample(pos_movies, no_sample)\n",
    "    pos_samples = torch.tensor(pos_samples, dtype=torch.long).to(device)\n",
    "    neg_samples = random.sample(neg_movies, no_sample)\n",
    "    neg_samples = torch.tensor(neg_samples, dtype=torch.long).to(device)\n",
    "    loss = bpr_loss(embeddings, users, pos_samples, neg_samples)\n",
    "    total_loss += loss\n",
    "    num_batches += 1\n",
    "    avg_loss = total_loss / num_batches\n",
    "\n",
    "    # Update progress bar with average loss\n",
    "    pbar.set_postfix({'Avg Loss': f'{avg_loss:.4f}'})\n",
    "    \n",
    "recall = recall_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "precision = precision_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "avg_loss = total_loss / len(test_user_ratings)\n",
    "print(f'Test Loss: {avg_loss:.4f}, Test Recall@{k}: {recall:.4f}, Test Precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
