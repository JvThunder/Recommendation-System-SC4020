{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvthunder/anaconda/envs/rec-sys/lib/python3.9/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/jvthunder/anaconda/envs/rec-sys/lib/python3.9/site-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZNSt15__exception_ptr13exception_ptr9_M_addrefEv\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/jvthunder/anaconda/envs/rec-sys/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from models.light_gcn import LightGCNStack\n",
    "from utils.light_gcn_utils import bpr_loss, evaluate, build_user_item_interactions, get_positive_negative_ratings, recall_at_k, precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = 'movielens-1m'\n",
    "users, items, train_ratings, test_ratings, items_features_tensor, user_features_tensor = load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users: 6040, num_items: 3883\n"
     ]
    }
   ],
   "source": [
    "num_users = users['userid'].nunique()\n",
    "num_items = items['itemid'].nunique()\n",
    "print(f\"num_users: {num_users}, num_items: {num_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39767/1560685500.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  train_edge_index = torch.tensor([train_user_ids, train_item_ids], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# Create edge index for bipartite graph for train set\n",
    "train_user_ids = train_ratings['userid'].values\n",
    "train_item_ids = train_ratings['itemid'].values + num_users \n",
    "train_edge_index = torch.tensor([train_user_ids, train_item_ids], dtype=torch.long)\n",
    "\n",
    "# Create edge index for bipartite graph for test set\n",
    "test_user_ids = test_ratings['userid'].values  \n",
    "test_item_ids = test_ratings['itemid'].values + num_users  \n",
    "test_edge_index = torch.tensor([test_user_ids, test_item_ids], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_item_dict = build_user_item_interactions(train_ratings)\n",
    "test_user_item_dict = build_user_item_interactions(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_threshold = 5\n",
    "negative_threshold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_ratings = get_positive_negative_ratings(train_user_item_dict, positive_threshold, negative_threshold)\n",
    "test_user_ratings = get_positive_negative_ratings(test_user_item_dict, positive_threshold, negative_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, user in enumerate(train_user_ratings):\n",
    "    train_user_ratings[i] = (user[0], [item + num_users for item in user[1]], [item + num_users for item in user[2]])\n",
    "\n",
    "for i, user in enumerate(test_user_ratings):\n",
    "    test_user_ratings[i] = (user[0], [item + num_users for item in user[1]], [item + num_users for item in user[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 384\n",
    "num_nodes = num_users + num_items\n",
    "no_user_features = user_features_tensor.size(1)\n",
    "no_item_features = items_features_tensor.size(1)\n",
    "\n",
    "num_layers = 10\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0005\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "user_features_tensor = user_features_tensor.to(device)\n",
    "items_features_tensor = items_features_tensor.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "\n",
    "model = LightGCNStack(num_nodes, no_user_features, no_item_features, embedding_dim, num_layers).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 8.00 GiB of which 6.73 GiB is free. Process 26860 has 17179869184.00 GiB memory in use. Process 32637 has 17179869184.00 GiB memory in use. Process 32759 has 17179869184.00 GiB memory in use. Process 32549 has 17179869184.00 GiB memory in use. Process 39536 has 17179869184.00 GiB memory in use. Process 39575 has 17179869184.00 GiB memory in use. Process 39716 has 17179869184.00 GiB memory in use. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 159.02 MiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_features_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems_features_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_edge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_at_k(train_user_ratings, embeddings, k\u001b[38;5;241m=\u001b[39mk, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      3\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_at_k(train_user_ratings, embeddings, k\u001b[38;5;241m=\u001b[39mk, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda/envs/rec-sys/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/envs/rec-sys/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Recommendation-System-SC4020/models/light_gcn.py:43\u001b[0m, in \u001b[0;36mLightGCNStack.forward\u001b[0;34m(self, user_feature, movie_feature, edge_index)\u001b[0m\n\u001b[1;32m     41\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [x]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[0;32m---> 43\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     all_embeddings\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Aggregate embeddings with factors a_k = 1/(k+1)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda/envs/rec-sys/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/envs/rec-sys/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Recommendation-System-SC4020/models/light_gcn.py:22\u001b[0m, in \u001b[0;36mLightGCN.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     19\u001b[0m norm \u001b[38;5;241m=\u001b[39m deg_inv_sqrt[row] \u001b[38;5;241m*\u001b[39m deg_inv_sqrt[col]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Start propagating messages.\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/tmp/models.light_gcn_LightGCN_propagate_emmqa0s4.py:150\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, norm, size)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage_and_aggregate\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not implemented\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m/tmp/models.light_gcn_LightGCN_propagate_emmqa0s4.py:92\u001b[0m, in \u001b[0;36mcollect\u001b[0;34m(self, edge_index, x, norm, size)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, Tensor):\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, j, x)\n\u001b[0;32m---> 92\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda/envs/rec-sys/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:267\u001b[0m, in \u001b[0;36mMessagePassing._index_select\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, index)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/envs/rec-sys/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:290\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)):\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m that are larger \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour node feature matrix and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda/envs/rec-sys/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:271\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_index_select_safe\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: Tensor, index: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 8.00 GiB of which 6.73 GiB is free. Process 26860 has 17179869184.00 GiB memory in use. Process 32637 has 17179869184.00 GiB memory in use. Process 32759 has 17179869184.00 GiB memory in use. Process 32549 has 17179869184.00 GiB memory in use. Process 39536 has 17179869184.00 GiB memory in use. Process 39575 has 17179869184.00 GiB memory in use. Process 39716 has 17179869184.00 GiB memory in use. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 159.02 MiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "embeddings = model(user_features_tensor, items_features_tensor, train_edge_index)\n",
    "recall = recall_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "precision = precision_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "\n",
    "print(\"Base recall:\", recall)\n",
    "print(\"Base precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 5972/5972 [00:28<00:00, 211.34it/s, Avg Loss=0.6931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.6931, Recall@10: 0.2459, Precision@10: 0.4360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 5972/5972 [00:28<00:00, 207.21it/s, Avg Loss=0.6884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 0.6884, Recall@10: 0.2919, Precision@10: 0.5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 5972/5972 [00:14<00:00, 411.13it/s, Avg Loss=0.6841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 0.6841, Recall@10: 0.2998, Precision@10: 0.5717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 5972/5972 [00:17<00:00, 349.55it/s, Avg Loss=0.6805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 0.6805, Recall@10: 0.3026, Precision@10: 0.5764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 5972/5972 [00:32<00:00, 185.09it/s, Avg Loss=0.6768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 0.6768, Recall@10: 0.3025, Precision@10: 0.5765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 5972/5972 [00:29<00:00, 200.73it/s, Avg Loss=0.6741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 0.6741, Recall@10: 0.3031, Precision@10: 0.5784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 5972/5972 [00:24<00:00, 241.25it/s, Avg Loss=0.6707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 0.6707, Recall@10: 0.3023, Precision@10: 0.5773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 5972/5972 [00:23<00:00, 252.81it/s, Avg Loss=0.6693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 0.6693, Recall@10: 0.3046, Precision@10: 0.5798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 5972/5972 [00:19<00:00, 307.42it/s, Avg Loss=0.6679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 0.6679, Recall@10: 0.3046, Precision@10: 0.5793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 5972/5972 [00:14<00:00, 399.15it/s, Avg Loss=0.6676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.6676, Recall@10: 0.3044, Precision@10: 0.5781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 5972/5972 [00:13<00:00, 453.21it/s, Avg Loss=0.6659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 0.6659, Recall@10: 0.3038, Precision@10: 0.5778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 5972/5972 [00:15<00:00, 389.46it/s, Avg Loss=0.6662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 0.6662, Recall@10: 0.3042, Precision@10: 0.5772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 5972/5972 [00:13<00:00, 428.78it/s, Avg Loss=0.6673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 0.6673, Recall@10: 0.3046, Precision@10: 0.5763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 5972/5972 [00:11<00:00, 517.04it/s, Avg Loss=0.6682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 0.6682, Recall@10: 0.3044, Precision@10: 0.5723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 5972/5972 [00:13<00:00, 429.07it/s, Avg Loss=0.6688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 0.6688, Recall@10: 0.3039, Precision@10: 0.5676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 5972/5972 [00:12<00:00, 474.44it/s, Avg Loss=0.6698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 0.6698, Recall@10: 0.3046, Precision@10: 0.5665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 5972/5972 [00:13<00:00, 438.25it/s, Avg Loss=0.6665]\n"
     ]
    }
   ],
   "source": [
    "calc_metrics_every = 1\n",
    "losses = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    pbar = tqdm(train_user_ratings, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    embeddings = model(user_features_tensor, items_features_tensor, train_edge_index)\n",
    "\n",
    "    for user_id, pos_items, neg_items in pbar:\n",
    "        no_sample = min(len(pos_items), len(neg_items))\n",
    "        users = torch.tensor([user_id] * no_sample, dtype=torch.long).to(device)\n",
    "        pos_samples = random.sample(pos_items, no_sample)\n",
    "        pos_samples = torch.tensor(pos_samples, dtype=torch.long).to(device)\n",
    "        neg_samples = random.sample(neg_items, no_sample)\n",
    "        neg_samples = torch.tensor(neg_samples, dtype=torch.long).to(device)\n",
    "        \n",
    "        loss = bpr_loss(embeddings, users, pos_samples, neg_samples)\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "        avg_loss = total_loss.item() / num_batches\n",
    "\n",
    "        pbar.set_postfix({'Avg Loss': f'{avg_loss:.4f}'})\n",
    "\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    if (epoch + 1) % calc_metrics_every == 0:\n",
    "        recall = recall_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "        precision = precision_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        avg_loss = total_loss / len(train_user_ratings)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Recall@{k}: {recall:.4f}, Precision@{k}: {precision:.4f}')\n",
    "    else:\n",
    "        avg_loss = total_loss / len(train_user_ratings)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.title('Train Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "plt.plot(recalls)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall@10')\n",
    "plt.title('Recall@10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "plt.plot(precisions)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision@10')\n",
    "plt.title('Precision@10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5539/5539 [00:06<00:00, 918.95it/s, Avg Loss=0.7661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7661, Test Recall@10: 0.1706, Test Precision@10: 0.5294\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "num_batches = 0\n",
    "pbar = tqdm(test_user_ratings)\n",
    "\n",
    "embeddings = model(user_features_tensor, items_features_tensor, test_edge_index)\n",
    "\n",
    "for user_id, pos_items, neg_items in pbar:\n",
    "    no_sample = min(len(pos_items), len(neg_items))\n",
    "    users = torch.tensor([user_id] * no_sample, dtype=torch.long).to(device)\n",
    "    pos_samples = random.sample(pos_items, no_sample)\n",
    "    pos_samples = torch.tensor(pos_samples, dtype=torch.long).to(device)\n",
    "    neg_samples = random.sample(neg_items, no_sample)\n",
    "    neg_samples = torch.tensor(neg_samples, dtype=torch.long).to(device)\n",
    "    loss = bpr_loss(embeddings, users, pos_samples, neg_samples)\n",
    "    total_loss += loss\n",
    "    num_batches += 1\n",
    "    avg_loss = total_loss / num_batches\n",
    "\n",
    "    # Update progress bar with average loss\n",
    "    pbar.set_postfix({'Avg Loss': f'{avg_loss:.4f}'})\n",
    "    \n",
    "recall = recall_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "precision = precision_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "avg_loss = total_loss / len(test_user_ratings)\n",
    "print(f'Test Loss: {avg_loss:.4f}, Test Recall@{k}: {recall:.4f}, Test Precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
