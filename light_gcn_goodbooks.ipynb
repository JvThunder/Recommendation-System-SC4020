{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvthunder/anaconda/envs/rec-sys/lib/python3.9/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/jvthunder/anaconda/envs/rec-sys/lib/python3.9/site-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZNSt15__exception_ptr13exception_ptr9_M_addrefEv\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/jvthunder/anaconda/envs/rec-sys/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from models.light_gcn import LightGCNStack\n",
    "from utils.light_gcn_utils import bpr_loss, evaluate, build_user_item_interactions, get_positive_negative_ratings, recall_at_k, precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = 'goodbooks-10k'\n",
    "users, items, train_ratings, test_ratings, items_features_tensor, user_features_tensor = load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users: 993, num_items: 754\n"
     ]
    }
   ],
   "source": [
    "num_users = users['userid'].nunique()\n",
    "num_items = items['itemid'].nunique()\n",
    "print(f\"num_users: {num_users}, num_items: {num_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39716/1560685500.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  train_edge_index = torch.tensor([train_user_ids, train_item_ids], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# Create edge index for bipartite graph for train set\n",
    "train_user_ids = train_ratings['userid'].values\n",
    "train_item_ids = train_ratings['itemid'].values + num_users \n",
    "train_edge_index = torch.tensor([train_user_ids, train_item_ids], dtype=torch.long)\n",
    "\n",
    "# Create edge index for bipartite graph for test set\n",
    "test_user_ids = test_ratings['userid'].values  \n",
    "test_item_ids = test_ratings['itemid'].values + num_users  \n",
    "test_edge_index = torch.tensor([test_user_ids, test_item_ids], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_item_dict = build_user_item_interactions(train_ratings)\n",
    "test_user_item_dict = build_user_item_interactions(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_threshold = 5\n",
    "negative_threshold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_ratings = get_positive_negative_ratings(train_user_item_dict, positive_threshold, negative_threshold)\n",
    "test_user_ratings = get_positive_negative_ratings(test_user_item_dict, positive_threshold, negative_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, user in enumerate(train_user_ratings):\n",
    "    train_user_ratings[i] = (user[0], [item + num_users for item in user[1]], [item + num_users for item in user[2]])\n",
    "\n",
    "for i, user in enumerate(test_user_ratings):\n",
    "    test_user_ratings[i] = (user[0], [item + num_users for item in user[1]], [item + num_users for item in user[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 384\n",
    "num_nodes = num_users + num_items\n",
    "no_user_features = user_features_tensor.size(1)\n",
    "no_item_features = items_features_tensor.size(1)\n",
    "\n",
    "num_layers = 10\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0005\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "user_features_tensor = user_features_tensor.to(device)\n",
    "items_features_tensor = items_features_tensor.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "\n",
    "model = LightGCNStack(num_nodes, no_user_features, no_item_features, embedding_dim, num_layers).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base recall: 0.1986429342703487\n",
      "Base precision: 0.3600730059627042\n"
     ]
    }
   ],
   "source": [
    "embeddings = model(user_features_tensor, items_features_tensor, train_edge_index)\n",
    "recall = recall_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "precision = precision_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "\n",
    "print(\"Base recall:\", recall)\n",
    "print(\"Base precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 961/961 [00:02<00:00, 345.73it/s, Avg Loss=4.0893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 4.0893, Recall@10: 0.1986, Precision@10: 0.3601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 961/961 [00:03<00:00, 305.65it/s, Avg Loss=3.6271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 3.6271, Recall@10: 0.2057, Precision@10: 0.3708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 961/961 [00:03<00:00, 278.40it/s, Avg Loss=3.3519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 3.3519, Recall@10: 0.2160, Precision@10: 0.3857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 961/961 [00:02<00:00, 457.28it/s, Avg Loss=3.0750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 3.0750, Recall@10: 0.2288, Precision@10: 0.4041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 961/961 [00:02<00:00, 468.46it/s, Avg Loss=2.7990]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 2.7990, Recall@10: 0.2466, Precision@10: 0.4261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 961/961 [00:01<00:00, 573.31it/s, Avg Loss=2.4814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 2.4814, Recall@10: 0.2682, Precision@10: 0.4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 961/961 [00:01<00:00, 507.21it/s, Avg Loss=2.2555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 2.2555, Recall@10: 0.2837, Precision@10: 0.4738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 961/961 [00:01<00:00, 585.39it/s, Avg Loss=1.9577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 1.9577, Recall@10: 0.3053, Precision@10: 0.5009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 961/961 [00:02<00:00, 425.01it/s, Avg Loss=1.8131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 1.8131, Recall@10: 0.3237, Precision@10: 0.5249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 961/961 [00:02<00:00, 461.00it/s, Avg Loss=1.6390]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 1.6390, Recall@10: 0.3440, Precision@10: 0.5511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 961/961 [00:02<00:00, 408.70it/s, Avg Loss=1.4600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 1.4600, Recall@10: 0.3684, Precision@10: 0.5822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 961/961 [00:02<00:00, 417.28it/s, Avg Loss=1.3060]\n"
     ]
    }
   ],
   "source": [
    "calc_metrics_every = 1\n",
    "losses = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    pbar = tqdm(train_user_ratings, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    embeddings = model(user_features_tensor, items_features_tensor, train_edge_index)\n",
    "\n",
    "    for user_id, pos_items, neg_items in pbar:\n",
    "        no_sample = min(len(pos_items), len(neg_items))\n",
    "        users = torch.tensor([user_id] * no_sample, dtype=torch.long).to(device)\n",
    "        pos_samples = random.sample(pos_items, no_sample)\n",
    "        pos_samples = torch.tensor(pos_samples, dtype=torch.long).to(device)\n",
    "        neg_samples = random.sample(neg_items, no_sample)\n",
    "        neg_samples = torch.tensor(neg_samples, dtype=torch.long).to(device)\n",
    "        \n",
    "        loss = bpr_loss(embeddings, users, pos_samples, neg_samples)\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "        avg_loss = total_loss.item() / num_batches\n",
    "\n",
    "        pbar.set_postfix({'Avg Loss': f'{avg_loss:.4f}'})\n",
    "\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    if (epoch + 1) % calc_metrics_every == 0:\n",
    "        recall = recall_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "        precision = precision_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        avg_loss = total_loss / len(train_user_ratings)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Recall@{k}: {recall:.4f}, Precision@{k}: {precision:.4f}')\n",
    "    else:\n",
    "        avg_loss = total_loss / len(train_user_ratings)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# make plots\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mlosses\u001b[49m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "# make plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.title('Train Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "plt.plot(recalls)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall@10')\n",
    "plt.title('Recall@10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "plt.plot(precisions)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision@10')\n",
    "plt.title('Precision@10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2540/2540 [00:05<00:00, 423.88it/s, Avg Loss=4.7785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.7785, Test Recall@10: 0.3739, Test Precision@10: 0.8034\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "num_batches = 0\n",
    "pbar = tqdm(test_user_ratings)\n",
    "\n",
    "embeddings = model(user_features_tensor, items_features_tensor, test_edge_index)\n",
    "\n",
    "for user_id, pos_items, neg_items in pbar:\n",
    "    no_sample = min(len(pos_items), len(neg_items))\n",
    "    users = torch.tensor([user_id] * no_sample, dtype=torch.long).to(device)\n",
    "    pos_samples = random.sample(pos_items, no_sample)\n",
    "    pos_samples = torch.tensor(pos_samples, dtype=torch.long).to(device)\n",
    "    neg_samples = random.sample(neg_items, no_sample)\n",
    "    neg_samples = torch.tensor(neg_samples, dtype=torch.long).to(device)\n",
    "    loss = bpr_loss(embeddings, users, pos_samples, neg_samples)\n",
    "    total_loss += loss\n",
    "    num_batches += 1\n",
    "    avg_loss = total_loss / num_batches\n",
    "\n",
    "    # Update progress bar with average loss\n",
    "    pbar.set_postfix({'Avg Loss': f'{avg_loss:.4f}'})\n",
    "    \n",
    "recall = recall_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "precision = precision_at_k(train_user_ratings, embeddings, k=k, device=device)\n",
    "avg_loss = total_loss / len(test_user_ratings)\n",
    "print(f'Test Loss: {avg_loss:.4f}, Test Recall@{k}: {recall:.4f}, Test Precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
